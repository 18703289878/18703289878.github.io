---
published: true
title: 西瓜书Chapter 1&2
category: Machine Learning
tags: 
  - Machine Learning
layout: post
---

开始机器学习的学习啦！

让我们从经典的西瓜书开始。

# 1.1 

人类通过“经验”来学习，是否可以设计一种算法让机器也来学习呢？机器学习便是一种这样的算法，说白了，机器学习就是一种`learning algorithm`，它教机器（computer）如何通过**数据集**（经验）来学习
得到模型。

# 1.2 terminology

了解一下机器学习里基本的术语。

	data set
	instance/sample
	attribute/feature
	training data\training set
	hypothesis\ground-truth
	label\example\lable space(label+sample=example)

* 预测离散值叫做**classification**。  
* 预测连续值叫做**regression**。

* supervised learning:classification and regression。
* unsupervised learning:clustering

# 1.3 科学推理

induction是一个generalization的过程。  
deduction是一个specialization的过程。

## inductive bias

inductive bias即是所谓归纳偏好。机器训练出来的“模型”不止一个的时候，我们要如何选择？（比如根据一系列点我们可以画出非常多条符合这些点的曲线）。  

## Occam's razor

Occam's razor即是所谓奥卡姆剃刀原则。即“有多个假设与观察一致，则选择最简单的那个.”，可以说是很简单粗暴了。

## NFL定理

什么是NFL定理？No Free Lunch Theorem。“没有免费的午餐定理”。假设我们有很多个学习算法，它们通过训练得到了不同的模型，也就是说，无论算法a多么的巧妙，算法b多么的简单，它们的期望性能是相同的。
它有一个重要的前提条件：所有问题同等重要。也就是说这么多模型里我们要选择当前问题最合适的。

# 2.1 empirical error and overfitting

error有两种，一种是training error，也叫empirical error，指的是与训练集的误差，另一种是generalization error，指的是与测试集的误差，后者可以用来评价模型泛化的能力。

所谓的error rate通常指代的是generalization error rate，`error rate=1-accuracy`。

那什么是overfitting和underfitting呢？西瓜书里的这张图非常形象。

![0](https://raw.githubusercontent.com/Logos23333/Logos23333.github.io/master/_posts/image/ml/0.png)

所谓overfitting过拟合就是指学习能力太强了，把属于这个训练集的不应该学到的特点也学进去了（如树叶的锯齿），而underfitting欠拟合则是指学习能力太弱。



