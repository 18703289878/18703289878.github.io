---
published: true
title: 对话系统论文笔记一
category: Dialogue System
tags: 
  - DL
  - DS
  - paper reading
layout: post
---





2019.10.24 开始尝试写对话系统的论文总结，每周都会更新，一周更新五篇论文左右。

2019.10.24 更新 Improving Neural Conversational Models with Entropy-Based Data Filtering

# Improving Neural Conversational Models with Entropy-Based Data Filtering

ACL 2019

## 总结

基于seq2seq架构的对话系统存在*倾向于生成generic回复*的问题，论文作者认为这是因为对话系统的数据集中存在`one to many`和`many to one`的复杂关系，也就是说，在对话系统中存在一个`source utterance`对应多个不同含义`target utterance`的情况（反之亦然），这会给对话系统带来困扰：我该学习哪个target呢？基于这种状况，文章提出了一种方法来清洗数据集中熵（Entropy）较高的`source-target pair`，文章中的熵是这样定义的，如果一个source对应多个target，那么此source的熵较高（也可以用同样的方式来计算target的熵）。注意到这里指的不同target仅仅是在表面上不同，即*i dont know* 和*I don't know.*这两个句子虽然只有个别单词不一样，含义一样，但是也视为不同的target。 所以从直觉上来看，这里是需要做聚类的，若有一个source同时对应上述两个target，那么这两个target应被视为一样的答案。但从实验上来看，做聚类之后再清洗数据效果反而不如原来好，作者分析说可能是因为聚类的效果不太好。还有一点值得注意的是，从实验效果上来看，清洗熵较高的`target`效果比清洗`source`好。

## 一点思考

这种数据清洗的方法有后续工作可以跟进吗？这篇文章是将过于generic的pair清洗掉，那么我在做persona-dialogue或者style-dialogue的时候是不是也能通过类似的方式，*把不想要的数据清洗掉*，用简单的`one-to-one`的模型得到我想要的response呢？

## 一点吐槽

论文的思想非常简单，可以说methods也并不复杂，但为什么就是能中ACL呢？人家实验用了17个自动指标，非常充分且详细啊。而且如果让我来写的话，我肯定是不会说用熵来计算，而只会想到frequency之类的很low的东西。

# Generating Multiple Diverse Responses with Multi-Mapping and Posterior Mapping Selection