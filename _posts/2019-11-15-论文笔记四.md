---
published: true
title: 对话系统论文笔记四：主题相关
category: Dialogue System
tags: 
  - DL
  - DS
  - paper reading
layout: post


---

2019.11.15 更新 Target-Guided Open-Domain Conversation

2019.11.15 更新 Proactive Human-Machine Conversation with Explicit Conversation Goals

2019.11.15 更新 Proactive Knowledge-Goals Dialogue System Based on Pointer Network

2019.11.15 更新 Learning to Ask Questions in Open-domain Conversational Systems with Typed Decoders



# Target-Guided Open-Domain Conversation

ACL 2019

## 总结

这篇文章想要解决的问题是：在对话的过程中由一个随机的topic(文章里简单把key word当作topic)逐渐转到一个给定的topic (target)。如下图所示

![target-guied](https://github.com/Logos23333/Logos23333.github.io/blob/master/_posts/image/paper/target-guided.png?raw=true)

在对话开始时agent有一个target topic `e-books`,而user最开始聊的是`tired`，在对话过程中，topic逐渐转移成`e-books`。

文章的模型非常简单，整个模型分成三个部分：

- keyword predictor: 这个module用监督学习的方法预测下一句的key word

- keyword selection: 进一步在上一个module得到的candicates里选择一个key word，此key word与target的相似度需要比原来的高，这样可以保证key word最后一定会收敛到target (cosine similarity)

- reponse retrieval: 用检索式的方法选择一个与key word最相关的response



# Proactive Human-Machine Conversation with Explicit Conversation Goals

ACL 2019

## 总结

这篇文章定义的问题是，给定context $X$，dialogue goal $G$ = [$start, topic\_a, topic\_b$]，related knowledge $K$，生成能完成dialogue goal及包含相关知识并与上下文有关的response $Y$。针对这个新问题，文章提出了一个新的数据集，这个数据集的每一个dialogue都由一个leader和follower人工生成，leader负责引导topic，而follower只作response。文章还针对此问题提出了模型，将knowledge和 goal等隐式编码，再经过几层处理最后得到response。看了文章我最大的疑惑就是，为什么将 dialogue goal隐式编码就能够进行话题的转移呢？在它的model里，dialogue goal甚至是和knowleage等一起编码的，很不可解释。有没有这么一种可能，这个user goal完全没有作用，只是因为这个数据集足够好，实验的结果才比较好看？相对来说，我很不喜欢这篇论文，不客气的讲，完全是拿钱堆出来的论文，对于读者而言没有启发。

# Proactive Knowledge-Goals Dialogue System Based on Pointer Network

NLPCC 2019

## 总结

这篇文章应该是打了百度的比赛，然后把自己比赛的模型拿出来投稿，但是文章有很多错漏，前后逻辑也有不通顺之处，数学符号不规范，最重要的是它motivation有讲如何引导topic，但是在model部分完全就是把自己的model罗列出来，根本没有进行解释，也没有与motivation形成对应关系。

无语。

# Learning to Ask Questions in Open-domain Conversational Systems with Typed Decoders

ACL 2018

## 总结

## 